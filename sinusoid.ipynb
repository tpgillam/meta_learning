{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "\n",
    "from contexttimer import Timer\n",
    "from matplotlib import pyplot\n",
    "from more_itertools.recipes import pairwise\n",
    "from typing import Collection, NamedTuple, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch(NamedTuple):\n",
    "    \"\"\"Represent a batch of tasks, returned by `generate_sinusoid_batch`.\"\"\"\n",
    "    x: numpy.ndarray  # (batch_size_meta, batch_size_inner)\n",
    "    y: numpy.ndarray  # (batch_size_meta, batch_size_inner)\n",
    "    amplitude: numpy.ndarray  # (batch_size_meta,)\n",
    "    phase: numpy.ndarray  # (batch_size_meta,)\n",
    "    input_range: Tuple[float, float]\n",
    "    amplitude_range: Tuple[float, float]\n",
    "\n",
    "\n",
    "def generate_sinusoid_batch(\n",
    "        batch_size_meta: int,\n",
    "        batch_size_inner: int,\n",
    "        amplitude_range: Tuple[float, float]=(0.1, 5.0),\n",
    "        phase_range: Tuple[float, float]=(0., numpy.pi),\n",
    "        input_range: Tuple[float, float]=(-5.0, 5.0)) -> Batch:\n",
    "    \"\"\"Compute a batch of samples.\n",
    "    \n",
    "    We draw `batch_size_meta` tasks, and for each task a batch of `batch_size_inner` points. Each \"task\"\n",
    "    represents a regression problem, underlied by a sine wave with some amplitude and phase.\n",
    "    \n",
    "    Args:\n",
    "        batch_size_meta: The number of tasks to draw.\n",
    "        batch_size_inner: The number of samples for each task.\n",
    "        amplitude_range: Draw the amplitude of the sine wave for the task uniformly from this range.\n",
    "        phase_range: Draw the phase of the sine wave for the task uniformly from this range.\n",
    "        input_range: The range from which the input variable will be drawn uniformly.\n",
    "    \"\"\"\n",
    "    amplitude = numpy.random.uniform(amplitude_range[0], amplitude_range[1], batch_size_meta)\n",
    "    phase = numpy.random.uniform(phase_range[0], phase_range[1], batch_size_meta)\n",
    "    \n",
    "    # All input locations are independent.\n",
    "    x = numpy.random.uniform(\n",
    "        input_range[0],\n",
    "        input_range[1],\n",
    "        (batch_size_meta, batch_size_inner))\n",
    "    \n",
    "    # To compute the outputs, we should broadcast the amplitude & phase over all inner samples.\n",
    "    y = numpy.expand_dims(amplitude, axis=1) * numpy.sin(x - numpy.expand_dims(phase, axis=1))\n",
    "    \n",
    "    return Batch(x, y, amplitude, phase, input_range, amplitude_range)\n",
    "\n",
    "\n",
    "def plot_task(batch: Batch, index: int):\n",
    "    \"\"\"Plot the task with the specified `index` from the given `batch`.\"\"\"\n",
    "    # Plot the reference curve\n",
    "    truth_x = numpy.linspace(batch.input_range[0], batch.input_range[1], 200)\n",
    "    truth_y = batch.amplitude[index] * numpy.sin(truth_x - batch.phase[index])\n",
    "    pyplot.plot(truth_x, truth_y, c='r', label='truth')\n",
    "    \n",
    "    # Plot the sample points.\n",
    "    pyplot.plot(batch.x[index], batch.y[index], '^', label='samples')\n",
    "    \n",
    "    pyplot.xlim(*batch.input_range)\n",
    "    max_y = max(batch.amplitude_range)\n",
    "    pyplot.ylim(-max_y, max_y)\n",
    "    \n",
    "    pyplot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = generate_sinusoid_batch(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_task(batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6283846 , -0.18770144, -4.09803082,  2.45289938,  3.22124447],\n",
       "       [ 1.63566076,  4.87131791,  0.48346901, -0.94792303, -0.12155327],\n",
       "       [ 4.47132699, -3.98549463, -2.14739351, -3.84989929,  0.76371055]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalRegressor(torch.nn.Module):\n",
    "    \"\"\"A module suitable for producing  \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_sizes: Collection[int]=(40, 40)):\n",
    "        super().__init__()\n",
    "        dim_in = 1\n",
    "        dim_out = 1\n",
    "        all_dims = (dim_in,) + tuple(hidden_sizes) + (dim_out,)\n",
    "        self.layers = [torch.nn.Linear(dim_1, dim_2) for dim_1, dim_2 in pairwise(all_dims)]\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            # Register this as a sub-module, so we declare the existence of the necessary parameters\n",
    "            torch.nn.init.xavier_normal_(layer.weight)\n",
    "            self.add_module(f'layer_{i}', layer)\n",
    "            \n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simple(\n",
    "        *,\n",
    "        use_reynolds_trick: bool,\n",
    "        num_epochs: int=50,\n",
    "        batch_size: int=1000,\n",
    "        learning_rate: float=1e-3,\n",
    "        verbose: bool=False) -> list:\n",
    "    device = get_device()\n",
    "    module = SinusoidalRegressor().to(device)\n",
    "    \n",
    "    \n",
    "    # print(model)\n",
    "\n",
    "    # Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "    # in the SGD constructor will contain the learnable parameters of the two\n",
    "    # nn.Linear modules which are members of the model.\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    \n",
    "    test_accuracies = []\n",
    "\n",
    "    numpy.random.seed(42)\n",
    "    \n",
    "    with Timer() as timer:\n",
    "        for i_epoch in range(num_epochs):\n",
    "            # Shuffle training data\n",
    "            index = numpy.arange(torch_train_x.shape[0])\n",
    "            numpy.random.shuffle(index)\n",
    "            shuffled_train_x = torch_train_x[index]\n",
    "            shuffled_train_y = torch_train_y[index]\n",
    "\n",
    "            num_batches = train_X.shape[0] // batch_size\n",
    "            for i_batch in range(num_batches):\n",
    "                # Create Tensors to hold inputs and outputs\n",
    "\n",
    "                i_start = i_batch * batch_size\n",
    "                i_end = i_start + batch_size\n",
    "                x = shuffled_train_x[i_start:i_end]\n",
    "                y = shuffled_train_y[i_start:i_end]\n",
    "\n",
    "                # Forward pass: Compute predicted y by passing x to the model\n",
    "                y_pred = model(x)\n",
    "\n",
    "                # Compute loss\n",
    "                loss = criterion(y_pred, y)\n",
    "\n",
    "                # Zero gradients, perform a backward pass, and update the weights.\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # At the end of each epoch print a summary\n",
    "            acc = accuracy(y_pred, y)\n",
    "\n",
    "            # No need to accumulate gradients when evaluating the validation loss.\n",
    "            # Also, we put the model into \"evaluation mode\" for the purpose of computing the prediction. This is\n",
    "            # to prevent layers like BatchNorm / Dropout mutating their internal state.\n",
    "            with torch.no_grad(), model_eval(model):\n",
    "                test_y_pred = model(torch_test_x)\n",
    "                test_accuracy = accuracy(test_y_pred, torch_test_y).item()\n",
    "                \n",
    "            test_accuracies.append(test_accuracy)\n",
    "            if verbose:\n",
    "                print(f'Epoch {i_epoch + 1}/{num_epochs}:   {100 * acc.item():.1f}%   {100 * test_accuracy:.1f}%')\n",
    "\n",
    "    print(timer)\n",
    "    return test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From code:\n",
    "batch_size_meta = 25\n",
    "\n",
    "# The inner batch size. It seems to vary between plots.\n",
    "# We actually generate *twice* this amount of data in total; half is used for the inner\n",
    "# training loop, and the other half for inner testing.\n",
    "update_batch_size_inner = 10\n",
    "\n",
    "learning_rate_meta = 0.001  # Meta Adam optimizer\n",
    "learning_rate_update = 0.001  # Inner Adam optimizer\n",
    "num_steps_train_meta = 70000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
